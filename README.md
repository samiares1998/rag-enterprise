# ðŸ§  RAG Enterprise Project

Proyecto base para construir un sistema **RAG (Retrieval-Augmented Generation)** en Python con FastAPI, LangChain y un vectorDB (Chroma, Pinecone o Qdrant).

## ðŸš€ Tech Stack

- **Backend**: [FastAPI](https://fastapi.tiangolo.com/) + [LangChain](https://www.langchain.com/)  
- **VectorDB**: ChromaDB / Pinecone / Qdrant  
- **LLM**: OpenAI GPT / modelos open-source (HuggingFace, Llama, etc.)  
- **Infra**: Docker + GitHub Actions (CI/CD)  
- **Tests**: Pytest  

---

## ðŸ“‚ Estructura de carpetas

```bash
rag-enterprise/
â”‚â”€â”€ .github/                  # CI/CD workflows
â”‚â”€â”€ docs/                     # DocumentaciÃ³n
â”‚â”€â”€ scripts/                  # Scripts auxiliares
â”‚â”€â”€ tests/                    # Tests unitarios e integraciÃ³n
â”‚
â”‚â”€â”€ app/
â”‚   â”‚â”€â”€ main.py                # Entry point FastAPI
â”‚   â”‚â”€â”€ config.py              # ConfiguraciÃ³n global
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                   # Endpoints
â”‚   â”‚   â””â”€â”€ v1/                # VersiÃ³n de la API
â”‚   â”‚       â”œâ”€â”€ rag_routes.py
â”‚   â”‚       â”œâ”€â”€ health.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/             # IngestiÃ³n de datos
â”‚   â”‚   â”œâ”€â”€ loaders.py
â”‚   â”‚   â”œâ”€â”€ processors.py
â”‚   â”‚   â””â”€â”€ embeddings.py
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/             # RecuperaciÃ³n de contexto
â”‚   â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â””â”€â”€ ranker.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services/              # LÃ³gica de negocio
â”‚   â”‚   â”œâ”€â”€ rag_service.py
â”‚   â”‚   â””â”€â”€ llm_service.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                # Pydantic schemas & domain models
â”‚   â”‚   â”œâ”€â”€ request_models.py
â”‚   â”‚   â”œâ”€â”€ response_models.py
â”‚   â”‚   â””â”€â”€ document.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                 # Helpers
â”‚   â”‚   â””â”€â”€ logging.py
â”‚   â”‚
â”‚   â””â”€â”€ __init__.py
â”‚
â”‚â”€â”€ frontend/                  # Opcional (React, Next.js, etc.)
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ pyproject.toml             # (opcional con poetry/pipenv)
â”‚â”€â”€ .env                       # Variables de entorno
â”‚â”€â”€ README.md
# rag-enterprise

##  Estructura para la Data

rag-enterprise/
â”‚â”€â”€ data/
â”‚   â”œâ”€â”€ raw/           # Documentos originales (PDF, Word, Excel, CSV, imÃ¡genes)
â”‚   â”‚   â”œâ”€â”€ pdfs/
â”‚   â”‚   â”œâ”€â”€ word/
â”‚   â”‚   â”œâ”€â”€ excel/
â”‚   â”‚   â”œâ”€â”€ csv/
â”‚   â”‚   â””â”€â”€ images/
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/     # Textos ya extraÃ­dos y normalizados
â”‚   â”‚   â”œâ”€â”€ ejemplo1.txt
â”‚   â”‚   â”œâ”€â”€ ejemplo2.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ chunks/        # Texto dividido en chunks (JSON, txt o parquet)
â”‚   â”‚   â””â”€â”€ ejemplo1_chunks.json
â”‚   â”‚
â”‚   â””â”€â”€ embeddings/    # Vectores listos para subir al VectorDB (opcional si no usas DB directa)
â”‚       â””â”€â”€ ejemplo1.npy


Ingesta de documentos
âœ… Objetivo

Procesar distintos formatos de documentos en texto plano, normalizarlos y dividirlos en chunks para preparar embeddings.

âœ… Tareas completadas

Soporte de mÃºltiples formatos:

PDFs â†’ pymupdf o pypdf

Word â†’ python-docx

Excel â†’ openpyxl

CSV â†’ pandas

ImÃ¡genes â†’ OCR con pytesseract o easyocr

Pipeline de procesamiento:

Lee todos los archivos de data/raw/* automÃ¡ticamente (sin especificar uno a uno).

Extrae texto y lo guarda en data/processed/.

Genera chunks con RecursiveCharacterTextSplitter y los guarda en data/chunks/.

Evita reprocesar: si ya existen .txt y .json, los reutiliza.

API REST con FastAPI:

POST /api/v1/ingestion/ingest-all â†’ procesa todos los documentos.

POST /api/v1/ingestion/ingest-file â†’ procesa un documento especÃ­fico.

Error handling unificado:

Cada error responde con estructura estÃ¡ndar:

{
  "code": "PROCESSING_ERROR",
  "error": "FileNotFoundError",
  "reason": "No such file or directory"
}

